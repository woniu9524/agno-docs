---
title: Agent with Streaming
---

## Code

```python cookbook/models/vllm/basic_stream.py
from agno.agent import Agent
from agno.models.vllm import vLLM

agent = Agent(
    model=vLLM(id="Qwen/Qwen2.5-7B-Instruct", top_k=20, enable_thinking=False),
    markdown=True,
)
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="安装依赖库">
    ```bash
    pip install -U agno openai vllm
    ```
  </Step>

  <Step title="启动 vLLM 服务器">
    ```bash
    vllm serve Qwen/Qwen2.5-7B-Instruct \
        --enable-auto-tool-choice \
        --tool-call-parser hermes \
        --dtype float16 \
        --max-model-len 8192 \
        --gpu-memory-utilization 0.9
    ```
  </Step>

  <Step title="运行 Agent">
    ```bash
    python cookbook/models/vllm/basic_stream.py
    ```
  </Step>
</Steps>