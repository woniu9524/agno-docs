---
title: 异步代理与流式输出
---

## 代码

```python cookbook/models/vllm/async_basic_stream.py
import asyncio

from agno.agent import Agent
from agno.models.vllm import vLLM

agent = Agent(model=vLLM(id="Qwen/Qwen2.5-7B-Instruct"), markdown=True)
asyncio.run(agent.aprint_response("写一个两句的恐怖故事", stream=True))
```

## 用法

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="安装库">
    ```bash
    pip install -U agno openai vllm
    ```
  </Step>

  <Step title="启动 vLLM 服务器">
    ```bash
    vllm serve Qwen/Qwen2.5-7B-Instruct \
        --enable-auto-tool-choice \
        --tool-call-parser hermes \
        --dtype float16 \
        --max-model-len 8192 \
        --gpu-memory-utilization 0.9
    ```
  </Step>

  <Step title="运行代理">
    ```bash
    python cookbook/models/vllm/async_basic_stream.py
    ```
  </Step>
</Steps>