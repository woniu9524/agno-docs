---
title: 捕获推理内容
---

本示例演示了在使用 `reasoning=True` 或设置特定的 `reasoning_model` 时，如何访问和打印 `reasoning_content`。
## 代码

```python cookbook/reasoning/agents/capture_reasoning_content_default_COT.py

from agno.agent import Agent
from agno.models.openai import OpenAIChat

print("\n=== 示例 1：使用 reasoning=True (默认 COT) ===\n")

# 创建带有 reasoning=True 的代理 (默认模型 COT)
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    reasoning=True,
    markdown=True,
)

# 运行代理 (非流式)
print("使用 reasoning=True 运行 (非流式)...")
response = agent.run("前 10 个自然数的和是多少？")

# 打印 reasoning_content
print("\n--- 响应中的 reasoning_content ---")
if hasattr(response, "reasoning_content") and response.reasoning_content:
    print(response.reasoning_content)
else:
    print("在响应中未找到 reasoning_content")


print("\n\n=== 示例 2：使用自定义 reasoning_model ===\n")

# 使用特定的 reasoning_model 创建代理
agent_with_reasoning_model = Agent(
    model=OpenAIChat(id="gpt-4o"),
    reasoning_model=OpenAIChat(id="gpt-4o"),  # 应默认为手动 COT
    markdown=True,
)

# 运行代理 (非流式)
print("指定 reasoning_model 运行 (非流式)...")
response = agent_with_reasoning_model.run(
    "前 10 个自然数的和是多少？"
)

# 打印 reasoning_content
print("\n--- 响应中的 reasoning_content ---")
if hasattr(response, "reasoning_content") and response.reasoning_content:
    print(response.reasoning_content)
else:
    print("在响应中未找到 reasoning_content")


print("\n\n=== 示例 3：流式处理 reasoning=True ===\n")

# 为流式处理创建一个新的代理
streaming_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    reasoning=True,
    markdown=True,
)

# 打印响应 (包括处理流式响应)
print("使用 reasoning=True 运行 (流式)...")
streaming_agent.print_response(
    "5! (阶乘) 的值是多少？",
    stream=True,
    show_full_reasoning=True,
)

# 在流式处理后从代理的 run_response 中访问 reasoning_content
print("\n--- 流式处理后代理的 run_response 中的 reasoning_content ---")
if (
    hasattr(streaming_agent, "run_response")
    and streaming_agent.run_response
    and hasattr(streaming_agent.run_response, "reasoning_content")
    and streaming_agent.run_response.reasoning_content
):
    print(streaming_agent.run_response.reasoning_content)
else:
    print("在流式处理后为代理的 run_response 未找到 reasoning_content")


print("\n\n=== 示例 4：流式处理 reasoning_model ===\n")

# 为流式处理创建一个新的带有 reasoning_model 的代理
streaming_agent_with_model = Agent(
    model=OpenAIChat(id="gpt-4o"),
    reasoning_model=OpenAIChat(id="gpt-4o"),
    markdown=True,
)

# 打印响应 (包括处理流式响应)
print("指定 reasoning_model 运行 (流式)...")
streaming_agent_with_model.print_response(
    "5! (阶乘) 的值是多少？",
    stream=True,
    show_full_reasoning=True,
)

# 在流式处理后从代理的 run_response 中访问 reasoning_content
print("\n--- 流式处理后代理的 run_response 中的 reasoning_content ---")
if (
    hasattr(streaming_agent_with_model, "run_response")
    and streaming_agent_with_model.run_response
    and hasattr(streaming_agent_with_model.run_response, "reasoning_content")
    and streaming_agent_with_model.run_response.reasoning_content
):
    print(streaming_agent_with_model.run_response.reasoning_content)
else:
    print("在流式处理后为代理的 run_response 未找到 reasoning_content")

```

## 使用方法

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="设置你的 API 密钥">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="安装库">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="运行示例">
    <CodeGroup>
    ```bash Mac
    python cookbook/reasoning/agents/capture_reasoning_content_default_COT.py
    ```

    ```bash Windows
    python cookbook/reasoning/agents/capture_reasoning_content_default_COT.py
    ```
    </CodeGroup>
  </Step>
</Steps>