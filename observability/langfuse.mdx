---
title: Langfuse
description: 集成 Agno 与 Langfuse，发送 trace 并深入了解您的 agent 性能。
---

## 集成 Agno 与 Langfuse

Langfuse 是一个强大的平台，用于追踪和监控 AI 模型调用。通过集成 Agno 与 Langfuse，您可以利用 OpenInference 和 OpenLIT 发送 trace，并深入了解您的 agent 性能。

## 先决条件

1. **安装依赖项**

   确保已安装必要的包：

   ```bash
   pip install agno openai langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-agno
   ```

2. **设置 Langfuse 账户**

   - 自行托管或在 [Langfuse](https://us.cloud.langfuse.com) 注册一个账户。
   - 从 Langfuse 控制面板获取您的公共 API 密钥和私有 API 密钥。

3. **设置环境变量**

   使用 Langfuse API 密钥配置您的环境：

   ```bash
   export LANGFUSE_PUBLIC_KEY=<your-public-key>
   export LANGFUSE_SECRET_KEY=<your-secret-key>
   ```

## 发送 Trace 到 Langfuse

- ### 示例：将 Langfuse 与 OpenInference 结合使用

   此示例演示了如何使用 OpenInference 为您的 Agno agent 添加 instrument，并向 Langfuse 发送 trace。

   ```python
   import base64
   import os

   from agno.agent import Agent
   from agno.models.openai import OpenAIChat
   from agno.tools.yfinance import YFinanceTools
   from openinference.instrumentation.agno import AgnoInstrumentor
   from opentelemetry import trace as trace_api
   from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
   from opentelemetry.sdk.trace import TracerProvider
   from opentelemetry.sdk.trace.export import SimpleSpanProcessor

   # 设置 Langfuse 的环境变量
   LANGFUSE_AUTH = base64.b64encode(
       f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
   ).decode()
   os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://us.cloud.langfuse.com/api/public/otel"
   os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"

   # 配置 tracer provider
   tracer_provider = TracerProvider()
   tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
   trace_api.set_tracer_provider(tracer_provider=tracer_provider)

   # 开始 instrument agno
   AgnoInstrumentor().instrument()

   # 创建并配置 agent
   agent = Agent(
       name="Stock Price Agent",
       model=OpenAIChat(id="gpt-4o-mini"),
       tools=[YFinanceTools()],
       instructions="You are a stock price agent. Answer questions in the style of a stock analyst.",
       debug_mode=True,
   )

   # 使用 agent
   agent.print_response("What is the current price of Tesla?")
   ```

- ### 示例：将 Langfuse 与 OpenLIT 结合使用

   此示例演示了如何通过 OpenLIT 使用 Langfuse 来追踪模型调用。

   ```python
   import base64
   import os

   from agno.agent import Agent
   from agno.models.openai import OpenAIChat
   from agno.tools.duckduckgo import DuckDuckGoTools
   from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
   from opentelemetry.sdk.trace import TracerProvider
   from opentelemetry.sdk.trace.export import SimpleSpanProcessor
   from opentelemetry import trace

   # 设置 Langfuse 的环境变量
   LANGFUSE_AUTH = base64.b64encode(
       f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
   ).decode()
   os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://us.cloud.langfuse.com/api/public/otel"
   os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"

   # 配置 tracer provider
   trace_provider = TracerProvider()
   trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
   trace.set_tracer_provider(trace_provider)

   # 初始化 OpenLIT instrumentation
   import openlit
   openlit.init(tracer=trace.get_tracer(__name__), disable_batch=True)

   # 创建并配置 agent
   agent = Agent(
       model=OpenAIChat(id="gpt-4o-mini"),
       tools=[DuckDuckGoTools()],
       markdown=True,
       debug_mode=True,
   )

   # 使用 agent
   agent.print_response("What is currently trending on Twitter?")
   ```

## 注意事项

- **环境变量**：确保为 API 密钥和 OTLP 端点正确设置了环境变量。
- **数据区域**：根据需要调整数据区域或本地部署的 `OTEL_EXPORTER_OTLP_ENDPOINT`。可用区域包括：
  - 美国区域的 `https://us.cloud.langfuse.com/api/public/otel`
  - 欧盟区域的 `https://eu.cloud.langfuse.com/api/public/otel`
  - 本地部署的 `http://localhost:3000/api/public/otel`

通过遵循这些步骤，您可以有效地集成 Agno 与 Langfuse，从而实现对 AI agent 的全面可观察性和监控。