---
title: OpenAI
description: Learn how to use OpenAI models in Agno.
---

The GPT models are the best in class LLMs and used as the default LLM by **Agents**. OpenAI supports a variety of world-class models. See their models [here](https://platform.openai.com/docs/models).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

- `gpt-4o` is good for most general use-cases.
- `gpt-4o-mini` model is good for smaller tasks and faster inference.
- `o1` models are good for complex reasoning and multi-step tasks.
- `o3-mini` is a strong reasoning model with support for tool-calling and structured outputs, but at a much lower cost.

OpenAI have tier based rate limits. See the [docs](https://platform.openai.com/docs/guides/rate-limits/usage-tiers) for more information.

## Authentication

Set your `OPENAI_API_KEY` environment variable. You can get one [from OpenAI here](https://platform.openai.com/account/api-keys).

<CodeGroup>

```bash Mac
export OPENAI_API_KEY=sk-***
```

```bash Windows
setx OPENAI_API_KEY sk-***
```

</CodeGroup>

## Example

Use `OpenAIChat` with your `Agent`:

<CodeGroup>

```python agent.py

from agno.agent import Agent, RunResponse
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    markdown=True
)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story.")

```

## Prompt caching

Prompt caching will happen automatically using our `OpenAIChat` model. You can read more about how OpenAI handle caching in [their docs](https://platform.openai.com/docs/guides/prompt-caching).

</CodeGroup>

<Note> View more examples [here](../examples/models/openai). </Note>

## Params

For more information, please refer to the [OpenAI docs](https://platform.openai.com/docs/api-reference/chat/create) as well.

<Snippet file="model-openai-params.mdx" />

`OpenAIChat` is a subclass of the [Model](/reference/models/model) class and has access to the same params.
