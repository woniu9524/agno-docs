---
title: Meta
---

Meta offers a suite of powerful multi-modal language models known for their strong performance across a wide range of tasks, including superior text understanding and visual intelligence. 

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

- `Llama-4-Scout-17B`: Excellent performance for most general tasks, including multi-modal scenarios.
- `Llama-3.3-70B`: Powerful instruction-following model for complex reasoning tasks.

Explore all the models [here](https://llama.developer.meta.com/docs/models).

## Authentication

Set your `LLAMA_API_KEY` environment variable:

<CodeGroup>
```bash Mac
export LLAMA_API_KEY=YOUR_API_KEY
```
```bash Windows
setx LLAMA_API_KEY YOUR_API_KEY
```
</CodeGroup>

## Example

Use `Llama` with your `Agent`:

<CodeGroup>
```python agent.py
from agno.agent import Agent
from agno.models.meta import Llama

agent = Agent(
    model=Llama(
        id="Llama-4-Maverick-17B-128E-Instruct-FP8",
    ),
    markdown=True
)

agent.print_response("Share a 2 sentence horror story.")
```
</CodeGroup>

<Note> View more examples [here](../examples/models/meta). </Note>

## Parameters

<Snippet file="model-meta-params.mdx" />

### OpenAI-like Parameters

`LlamaOpenAI` supports all parameters from [OpenAI Like](/reference/models/openai_like).

## Resources

- [Meta AI Models](https://llama.developer.meta.com/docs/models)
- [Llama API Documentation](https://llama.developer.meta.com/docs/overview)